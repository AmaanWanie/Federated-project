{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0c6ob2QdIla"
   },
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /home/wani/.local/lib/python3.10/site-packages (from scikit-learn) (2.1.3)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XT0qy_zSs37s"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import OrderedDict\n",
    "from PIL import Image  \n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "uuieeeuvul5-"
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, split='train', max_images_per_class=200):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory containing the dataset.\n",
    "            transform (callable, optional): Optional transform to be applied on an image.\n",
    "            split (str): Which part of the dataset to use ('train' or 'val').\n",
    "            max_images_per_class (int, optional): Limit the number of images per class.\n",
    "                                                   If None, uses all images.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.max_images_per_class = max_images_per_class\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dir))  # Get sorted class names (diseases)\n",
    "        self.class_map = {cls: idx for idx, cls in enumerate(self.classes)}  # Map class names to labels\n",
    "\n",
    "        # Prepare images and labels based on class directories\n",
    "        for class_name in self.classes:\n",
    "            class_folder = os.path.join(root_dir, class_name)\n",
    "            all_images = os.listdir(class_folder)\n",
    "\n",
    "            # If max_images_per_class is specified, take only the first `max_images_per_class` images\n",
    "            if self.max_images_per_class:\n",
    "                random.shuffle(all_images)  # Shuffle to ensure randomness\n",
    "                selected_images = all_images[:self.max_images_per_class]\n",
    "            else:\n",
    "                selected_images = all_images  # Take all images if no limit is set\n",
    "\n",
    "            for img_name in selected_images:\n",
    "                img_path = os.path.join(class_folder, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(self.class_map[class_name])\n",
    "\n",
    "        # Split data into train and validation sets\n",
    "        train_images, val_images, train_labels, val_labels = train_test_split(self.images, self.labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        if self.split == 'train':\n",
    "            self.images = train_images\n",
    "            self.labels = train_labels\n",
    "        else:\n",
    "            self.images = val_images\n",
    "            self.labels = val_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "J_MTeLFLvBSs"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# Path to your dataset\n",
    "hospitals_root = '/mnt/c/Users/Dell/Desktop/github/Federated-Learning/Hospitals_Dataset'\n",
    "hospital_dirs = [os.path.join(hospitals_root, f'Hospital_{i+1}') for i in range(3)]  # assuming you have 3 hospitals\n",
    "\n",
    "# Create data loaders for each hospital (client) with separate training and validation sets\n",
    "hospital_train_loaders = []\n",
    "hospital_val_loaders = []\n",
    "\n",
    "for hospital_dir in hospital_dirs:\n",
    "    # Create training and validation datasets for each hospital\n",
    "    dataset_train = CustomDataset(hospital_dir, transform=transform, split='train')\n",
    "    dataset_val = CustomDataset(hospital_dir, transform=transform, split='val')\n",
    "\n",
    "    # Create data loaders for training and validation sets\n",
    "    train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(dataset_val, batch_size=32, shuffle=False)\n",
    "\n",
    "    hospital_train_loaders.append(train_loader)\n",
    "    hospital_val_loaders.append(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QCppt-ncuzm7"
   },
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Load a pretrained ResNet18 model\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Modify the fully connected layer to include dropout\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(self.model.fc.in_features, 512),  # 512 hidden units\n",
    "            nn.ReLU(),  # Activation function\n",
    "            nn.Dropout(0.2),  # Dropout with 20% probability\n",
    "            nn.Linear(512, num_classes)  # Output layer for classification\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Z_x-2JhZu32P"
   },
   "outputs": [],
   "source": [
    "# Initialize models and optimizers for each hospital\n",
    "client_models = [CNNModel(num_classes=len(os.listdir(hospital_dirs[0]))) for _ in range(3)]  # Assuming same number of classes across hospitals\n",
    "client_models = [model.to(device) for model in client_models]\n",
    "optimizers = [optim.SGD(model.parameters(), lr=0.01, momentum=0.9) for model in client_models]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xNwN7oCDvMXl"
   },
   "outputs": [],
   "source": [
    "# Modify the client_update function to include validation\n",
    "def client_update(model, optimizer, train_loader, val_loader, epoch=1):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Train loop\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    #print(f\"Epoch {epoch} training completed. Average loss: {average_loss:.4f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "        validation_accuracy = correct / total\n",
    "    #print(f\"Epoch {epoch} validation accuracy: {validation_accuracy:.4f}\")\n",
    "\n",
    "    return average_loss, validation_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dOevx-PTvTU7"
   },
   "outputs": [],
   "source": [
    "# Aggregation function (simple averaging of model weights)\n",
    "def server_aggregate(global_model, client_models, hospital_train_loaders):\n",
    "    # Compute weights based on dataset sizes\n",
    "    weights = [len(loader.dataset) for loader in hospital_train_loaders]\n",
    "    total_weight = sum(weights)\n",
    "    weights = [w / total_weight for w in weights]\n",
    "\n",
    "    # Initialize global model state\n",
    "    global_state = global_model.state_dict()\n",
    "    for key in global_state.keys():\n",
    "        global_state[key] = sum(weights[i] * client_models[i].state_dict()[key] for i in range(len(client_models)))\n",
    "\n",
    "    # Update global model\n",
    "    global_model.load_state_dict(global_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JIpgu8mn4bsk"
   },
   "outputs": [],
   "source": [
    "def test(model, hospital_val_loaders):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_loader in hospital_val_loaders:\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return loss.item(), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppZp034TvY_d",
    "outputId": "da1e2650-589c-4c6b-edd0-0b27fc5da2d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Round 1/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.8438\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.9125\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.8438\n",
      "Aggregated global model after round 1\n",
      "Aggregated global validation loss: 0.8558, global validation accuracy: 0.8021\n",
      "------------------Round 2/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.9313\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.9250\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.8938\n",
      "Aggregated global model after round 2\n",
      "Aggregated global validation loss: 0.8072, global validation accuracy: 0.8854\n",
      "------------------Round 3/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.9375\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.9437\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.9062\n",
      "Aggregated global model after round 3\n",
      "Aggregated global validation loss: 0.7692, global validation accuracy: 0.9062\n",
      "------------------Round 4/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.9187\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.9187\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.9187\n",
      "Aggregated global model after round 4\n",
      "Aggregated global validation loss: 0.7878, global validation accuracy: 0.8958\n",
      "------------------Round 5/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.9187\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.8250\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.9187\n",
      "Aggregated global model after round 5\n",
      "Aggregated global validation loss: 0.8188, global validation accuracy: 0.8812\n",
      "------------------Round 6/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.9187\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.9062\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.9250\n",
      "Aggregated global model after round 6\n",
      "Aggregated global validation loss: 0.8000, global validation accuracy: 0.8875\n",
      "------------------Round 7/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.9375\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.9125\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.9062\n",
      "Aggregated global model after round 7\n",
      "Aggregated global validation loss: 0.7574, global validation accuracy: 0.9021\n",
      "------------------Round 8/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.9250\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.9375\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.9125\n",
      "Aggregated global model after round 8\n",
      "Aggregated global validation loss: 0.7395, global validation accuracy: 0.9042\n",
      "------------------Round 9/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.9187\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.9125\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.9000\n",
      "Aggregated global model after round 9\n",
      "Aggregated global validation loss: 0.7540, global validation accuracy: 0.8875\n",
      "------------------Round 10/10--------------------------\n",
      "Training on Hospital 1\n",
      "Validation accuracy for Hospital 1: 0.9313\n",
      "Training on Hospital 2\n",
      "Validation accuracy for Hospital 2: 0.9125\n",
      "Training on Hospital 3\n",
      "Validation accuracy for Hospital 3: 0.9125\n",
      "Aggregated global model after round 10\n",
      "Aggregated global validation loss: 0.7112, global validation accuracy: 0.9000\n",
      "CPU times: user 3h 53min 25s, sys: 1min 58s, total: 3h 55min 23s\n",
      "Wall time: 51min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Federated training loop\n",
    "global_model = CNNModel(num_classes=len(os.listdir(hospital_dirs[0]))).to(device)\n",
    "num_rounds = 10  # Federated learning rounds\n",
    "epochs = 10  # Number of local epochs per client\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    print(f\"------------------Round {round + 1}/{num_rounds}--------------------------\")\n",
    "\n",
    "    # Train on each hospital's dataset (client-specific training)\n",
    "    for client_idx, (train_loader, val_loader) in enumerate(zip(hospital_train_loaders, hospital_val_loaders)):\n",
    "        print(f\"Training on Hospital {client_idx + 1}\")\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            loss, val_accuracy = client_update(client_models[client_idx], optimizers[client_idx], train_loader, val_loader, epoch=epoch)\n",
    "        print(f\"Validation accuracy for Hospital {client_idx + 1}: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Aggregate the models with weighted averaging (after all clients' updates)\n",
    "    server_aggregate(global_model, client_models, hospital_train_loaders)\n",
    "    print(f\"Aggregated global model after round {round + 1}\")\n",
    "\n",
    "    # Compute global validation accuracy for the aggregated global model\n",
    "    global_val_loss, global_val_accuracy = test(global_model, hospital_val_loaders)\n",
    "    print(f\"Aggregated global validation loss: {global_val_loss:.4f}, global validation accuracy: {global_val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "y5bmMVF9G6Cy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global model saved to global_model.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_save_path = 'global_model.pth'\n",
    "torch.save(global_model.state_dict(), model_save_path)\n",
    "print(f\"Global model saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
